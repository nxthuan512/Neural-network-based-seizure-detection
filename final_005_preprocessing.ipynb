{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. Read the dataset including N-clip ictal and M-clip interictal samples.\n",
    "2. Parse the header and content. Label each timestep as 0 or 1.\n",
    "3. Slipt the content into 5-fold so that train and test sets are 80% and 20%, respectively.\n",
    "4. Oversample minority class in train sets\n",
    "5. Standardize the train sets. Get the common mean and standard deviation for test sets. \n",
    "6. Create one train and test set by concantenating and then suffling ictal and interictal set.\n",
    "7. Store 5 datasets in 5 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "import argparse\n",
    "import datetime as dt\n",
    "import random\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subject:\n",
    "    def __init__(self, ictal_sample, interictal_sample, n_timestep, n_feature): \n",
    "        self.ictal_sample = ictal_sample\n",
    "        self.interictal_sample = interictal_sample\n",
    "        self.sfreq = n_timestep\n",
    "        self.nfeat = n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Low pass filter\n",
    "# =================================================\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling ictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1) Parse all ictal and interictal files\n",
    "# 2) Oversample ictal\n",
    "# 3) Store their contents into 2 seperate arrays \n",
    "# ============================================\n",
    "def xt_load_rawdata(subject, filter_en, resample_en, dir_in): \n",
    "    mark = ['ictal', 'interictal']\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Step 1, 2\n",
    "    # -------------------------------------------------------\n",
    "    # Obtain frequence bands\n",
    "    if filter_en == 1:\n",
    "        n_band = 5\n",
    "    else:\n",
    "        n_band = 1\n",
    "     \n",
    "    # Resample patient 5000 Hz to 500 Hz\n",
    "    if resample_en == 1:\n",
    "        s_freq = int(subject.sfreq / 10)\n",
    "    else:\n",
    "        s_freq = subject.sfreq\n",
    "    \n",
    "    Xic = np.zeros((subject.ictal_sample, s_freq, subject.nfeat * n_band))\n",
    "    Xit = np.zeros((subject.interictal_sample, s_freq, subject.nfeat * n_band))\n",
    "    yic = np.zeros((subject.ictal_sample, s_freq, n_band))\n",
    "    yit = np.zeros((subject.interictal_sample, s_freq, n_band))\n",
    "    \n",
    "    for i in range (0, 2):\n",
    "        #\n",
    "        if mark[i] == 'ictal':\n",
    "            end_fileID = subject.ictal_sample + 1\n",
    "            data_path_in = dir_in + '_ictal_segment_'\n",
    "        else:\n",
    "            end_fileID = subject.interictal_sample + 1\n",
    "            data_path_in = dir_in + '_interictal_segment_'\n",
    "         \n",
    "        #\n",
    "        for file_id in range (1, end_fileID):\n",
    "            file_in = data_path_in + str(file_id) + '.mat' \n",
    "\n",
    "            mat = spio.loadmat(file_in)\n",
    "\n",
    "            # Number of channels\n",
    "            n_channel = len(mat['channels'][0][0])\n",
    "            # Sampling frequency\n",
    "            s_freq = mat['freq']\n",
    "            # Number of samples\n",
    "            n_sample = int(np.round(s_freq))\n",
    "\n",
    "            # ----------------------------------\n",
    "            if filter_en == 1:\n",
    "                # Band-pass filter\n",
    "                order = 6\n",
    "                lowcut_freq = [1, 4, 8, 12, 30]\n",
    "                highcut_freq = [4, 8, 12, 30, 64]\n",
    "                X = np.zeros((n_channel * n_band, subject.sfreq))\n",
    "                for j in range (0, n_channel):\n",
    "                    kk = j*5\n",
    "                    for k in range (0, 5):\n",
    "                        X[kk + k] = butter_bandpass_filter(mat['data'][j], lowcut_freq[k], highcut_freq[k], \\\n",
    "                                                           subject.sfreq, order)\n",
    "                X = X.T\n",
    "                \n",
    "            elif resample_en == 1:\n",
    "                # Resample 5000 Hz to 500 Hz\n",
    "                X = np.zeros((n_channel, 500))\n",
    "                if n_sample == 5000:\n",
    "                    for j in range (0, n_channel):\n",
    "                        kk = 0\n",
    "                        for k in range (0, subject.sfreq, 10):\n",
    "                            X[j][kk] = mat['data'][j][k]\n",
    "                            #X[j][kk] = np.average(mat['data'][j][k:k+10]) \n",
    "                            kk = kk+1\n",
    "                    X = X.T\n",
    "                    n_sample = 500\n",
    "            else:\n",
    "                X = mat['data'].T\n",
    "                \n",
    "            # ----------------------------------\n",
    "            # Latency only in ICTAL\n",
    "            if mark[i] == 'ictal':\n",
    "                # Latency\n",
    "                latency = int(mat['latency'])\n",
    "\n",
    "                #print(file_id, ': Channel numbers =', n_channel, 'Sampling frequency =', s_freq, \\\n",
    "                #      'Resampling frequency =', n_sample, 'Latency =', latency);\n",
    "                y = np.ones((n_sample, 1))\n",
    "\n",
    "            # No latency in INTERICTAL\n",
    "            else:\n",
    "                #print(file_id, ': Channel numbers =', n_channel, 'Sampling frequency =', s_freq, \\\n",
    "                #      'Resampling frequency =', n_sample);\n",
    "                y = np.zeros((n_sample, 1))\n",
    "            \n",
    "            # ---------------------------------- \n",
    "            if mark[i] == 'ictal':\n",
    "                Xic[file_id-1] = X\n",
    "                yic[file_id-1] = y\n",
    "            else:\n",
    "                Xit[file_id-1] = X\n",
    "                yit[file_id-1] = y \n",
    "                \n",
    "    #Xic_tmp = np.asarray(Xic )\n",
    "    #dim = Xic_tmp.shape\n",
    "    #Xic_tmp = Xic_tmp.reshape((dim[0] * dim[1]), dim[2])\n",
    "    #np.savetxt('./Results_copy1/tmpXic', Xic_tmp, fmt = '%.4f')        \n",
    "    #np.savetxt('./Results_copy1/tmpXit', Xic, fmt = '%.4f') \n",
    "\n",
    "    if resample_en == 1:\n",
    "        subject.sfreq = 500\n",
    "    return Xic, yic, Xit, yit\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1) Use K-fold function to slipt data 5 times\n",
    "# 2) Oversample ictal\n",
    "# 4) Concantenate ictal and interictal\n",
    "# 5) Standardize each fold, calculate average mean and standard deviation for all test sets\n",
    "# 6) Suffle and store 5 arrays into 5 files\n",
    "# ============================================\n",
    "def xt_prep_dataset(subject, dir_ou, k, Xic, yic, Xit, yit, std, filter_en, shuffle_train_en):    # std = 1: standardize\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Step 1 \n",
    "    # -------------------------------------------------------\n",
    "    if filter_en == 1:\n",
    "        n_band = 5\n",
    "    else:\n",
    "        n_band = 1\n",
    "        \n",
    "    kf = KFold(n_splits=k) # Define the split - into 5 folds   \n",
    "    \n",
    "    Xic_train = []\n",
    "    Xit_train = []\n",
    "    yic_train = []\n",
    "    yit_train = []\n",
    "    \n",
    "    Xic_test  = []\n",
    "    Xit_test  = []\n",
    "    yic_test  = []\n",
    "    yit_test  = []\n",
    "      \n",
    "    for train_index, test_index in kf.split(Xic): \n",
    "        Xic_train.append(Xic[train_index])\n",
    "        yic_train.append(yic[train_index])   \n",
    "        Xic_test.append(Xic[test_index])\n",
    "        yic_test.append(yic[test_index])\n",
    "        \n",
    "    for train_index, test_index in kf.split(Xit):\n",
    "        Xit_train.append(Xit[train_index])\n",
    "        yit_train.append(yit[train_index])\n",
    "        Xit_test.append(Xit[test_index])\n",
    "        yit_test.append(yit[test_index])                       \n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Step 2\n",
    "    # -------------------------------------------------------\n",
    "    n_tmp = subject.interictal_sample / subject.ictal_sample\n",
    "    \n",
    "    # Shift value \n",
    "    #n_shift = int(subject.sfreq / (subject.interictal_sample / subject.ictal_sample))\n",
    "    n_shift = int(subject.sfreq / n_tmp)\n",
    "    \n",
    "    # How difference interictal vs ictal\n",
    "    n_ict_int = int(np.round(n_tmp))\n",
    "    if n_ict_int > n_tmp:\n",
    "        n_tmp = 0\n",
    "    else:\n",
    "        n_tmp = 1\n",
    "    \n",
    "    print('--- --- Debug: n_ict_int, n_shift =', n_ict_int, n_shift)\n",
    "    Xic_train_gen = []\n",
    "    yic_train_gen = []\n",
    "    for i in range (0, k):\n",
    "        # Reshape\n",
    "        Xic_train_tmp = np.asarray(Xic_train[i])\n",
    "        dim = Xic_train_tmp.shape\n",
    "        Xic_train_tmp = Xic_train_tmp.reshape((dim[0] * dim[1]), dim[2])\n",
    "        global_start_id = n_shift\n",
    "        # In case 2 class are still different, make it balance\n",
    "        n_sub = dim[0] * (n_ict_int + n_tmp) - int(subject.interictal_sample * 0.8)\n",
    "        \n",
    "        # Add new samples to Xic_train\n",
    "        tmp_XX = []\n",
    "        tmp_YY = []\n",
    "        for j in range (0, n_ict_int): \n",
    "            start_id = global_start_id   \n",
    "            \n",
    "            #\n",
    "            if j == n_ict_int - 1:\n",
    "                end_id = start_id + (dim[0]-1-n_sub) * subject.sfreq\n",
    "                #print('dim, n_sub, start_id, end_id, subject.sfreq, Xic_train_tmp[start_id:end_id].shape =', \\\n",
    "                #  dim, n_sub, start_id, end_id, subject.sfreq, Xic_train_tmp[start_id:end_id].shape) \n",
    "                tmp_X = Xic_train_tmp[start_id:end_id,:].reshape((dim[0]-1-n_sub, subject.sfreq, dim[2]))\n",
    "                tmp_Y = np.ones((dim[0]-1-n_sub, subject.sfreq, n_band))\n",
    "            else:\n",
    "                end_id = start_id + (dim[0]-1) * subject.sfreq\n",
    "                tmp_X = Xic_train_tmp[start_id:end_id,:].reshape((dim[0]-1, subject.sfreq, dim[2]))\n",
    "                tmp_Y = np.ones((dim[0]-1, subject.sfreq, n_band))\n",
    "                \n",
    "            if j == 0:\n",
    "                tmp_XX = tmp_X\n",
    "                tmp_YY = tmp_Y\n",
    "            else: \n",
    "                tmp_XX = np.concatenate((tmp_XX, tmp_X), axis=0)\n",
    "                tmp_YY = np.concatenate((tmp_YY, tmp_Y), axis=0)\n",
    "                \n",
    "            global_start_id = global_start_id + n_shift\n",
    "        \n",
    "        #print(tmp_XX.shape, tmp_YY.shape) \n",
    "        Xic_train_gen.append(tmp_XX)\n",
    "        yic_train_gen.append(tmp_YY)\n",
    " \n",
    "    # -------------------------------------------------------\n",
    "    # Step 3, 4, 5\n",
    "    # -------------------------------------------------------\n",
    "    # Standardize train and test datasets\n",
    "    X_mean = []\n",
    "    X_std = [] \n",
    "    for i in range (0, k): \n",
    "        X_train = np.concatenate((Xic_train[i], Xic_train_gen[i], Xit_train[i]), axis = 0)\n",
    "        y_train = np.concatenate((yic_train[i], yic_train_gen[i], yit_train[i]), axis = 0)\n",
    "        X_test = np.concatenate((Xic_test[i], Xit_test[i]), axis = 0)\n",
    "        y_test = np.concatenate((yic_test[i], yit_test[i]), axis = 0)\n",
    "\n",
    "        X_train = np.asarray(X_train)\n",
    "        y_train = np.asarray(y_train)\n",
    "        X_test = np.asarray(X_test)\n",
    "        y_test = np.asarray(y_test)\n",
    "        \n",
    "        dim_Xtr = X_train.shape\n",
    "        dim_ytr = y_train.shape\n",
    "        dim_Xte = X_test.shape \n",
    "        dim_yte = y_test.shape\n",
    "        \n",
    "        #print('------ Debug =', dim_Xtr, dim_ytr, dim_Xte, dim_yte)         \n",
    "\n",
    "        # ---------------------------\n",
    "        if std == 1:\n",
    "            # 3D to 2D -> Standardize -> 2D to 3D\n",
    "            # 3D to 2D\n",
    "            X_train = X_train.reshape((dim_Xtr[0]*dim_Xtr[1]), dim_Xtr[2])\n",
    "            y_train = y_train.reshape((dim_ytr[0]*dim_ytr[1]), dim_ytr[2])\n",
    "            X_test = X_test.reshape((dim_Xte[0]*dim_Xte[1]), dim_Xte[2])\n",
    "            y_test = y_test.reshape((dim_yte[0]*dim_yte[1]), dim_yte[2])\n",
    "\n",
    "            # Standardize\n",
    "            scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "            X_mean.append(scaler.mean_)\n",
    "            X_std.append(scaler.scale_)\n",
    "\n",
    "            X_train_scaled = scaler.transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "            # 2D to 3D\n",
    "            X_train = X_train_scaled.reshape(dim_Xtr[0], dim_Xtr[1], dim_Xtr[2])\n",
    "            y_train = y_train.reshape(dim_ytr[0], dim_ytr[1], dim_ytr[2])\n",
    "            X_test = X_test_scaled.reshape(dim_Xte[0], dim_Xte[1], dim_Xte[2])\n",
    "            y_test = y_test.reshape(dim_yte[0], dim_yte[1], dim_yte[2])\n",
    "\n",
    "        # --------------------------------\n",
    "        # Suffle -> 3D to 2D -> Store to file\n",
    "        # Shuffle\n",
    "        if shuffle_train_en == 1:\n",
    "            X_train, y_train = shuffle(X_train, y_train, random_state=29)\n",
    "            #X_test, y_test = shuffle(X_test, y_test, random_state=2)\n",
    "            print('------ Shuffle, Debug =', i, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        else:\n",
    "            print('------ No shuffle, Debug =', i, X_train.shape, y_train.shape, X_test.shape, y_test.shape)                 \n",
    "\n",
    "        # 3D to 2D \n",
    "        X_train  = X_train.reshape((dim_Xtr[0]*dim_Xtr[1]), dim_Xtr[2])\n",
    "        y_train = y_train.reshape((dim_ytr[0]*dim_ytr[1]), dim_ytr[2])\n",
    "        X_test  = X_test.reshape((dim_Xte[0]*dim_Xte[1]), dim_Xte[2])\n",
    "        y_test = y_test.reshape((dim_yte[0]*dim_yte[1]), dim_yte[2])\n",
    "\n",
    "        # Store to file\n",
    "        file_ou = dir_ou + 'train_' + str(i)\n",
    "        np.savetxt(file_ou, np.hstack((X_train, y_train)), fmt = '%.4f')   \n",
    "        file_ou = dir_ou + 'test_' + str(i)\n",
    "        np.savetxt(file_ou, np.hstack((X_test, y_test)), fmt = '%.4f') \n",
    " \n",
    "    #print(X_mean, X_std) \n",
    "\n",
    "# =========================================================\n",
    "# Test function\n",
    "# =========================================================\n",
    "# ------------------------------------------------\n",
    "# User setting\n",
    "norm_en = 1\n",
    "filter_en = 0\n",
    "shuffle_train_en = 1\n",
    "test_subject_id = 'Patient_6' # Dog_1, ..., Patient_1, ...\n",
    "                             \n",
    "# ------------------------------------------------\n",
    "if test_subject_id == 'Dog_1' or test_subject_id == 'Dog_2' or \\\n",
    "    test_subject_id == 'Dog_3' or test_subject_id == 'Dog_4' or \\\n",
    "     test_subject_id == 'Patient_1':\n",
    "    resample_en = 0\n",
    "else:\n",
    "    resample_en = 1\n",
    "\n",
    "if test_subject_id == 'Dog_1':                            \n",
    "    test_subject = subject(178, 418, 400, 16)\n",
    "elif test_subject_id == 'Dog_2': \n",
    "    test_subject = subject(172, 1148, 400, 16)\n",
    "elif test_subject_id == 'Dog_3':\n",
    "    test_subject = subject(480, 4760, 400, 16)\n",
    "elif test_subject_id == 'Dog_4':\n",
    "    test_subject = subject(257, 2790, 400, 16)\n",
    "elif test_subject_id == 'Patient_1':\n",
    "    test_subject = subject(70, 104, 500, 68)\n",
    "elif test_subject_id == 'Patient_2':\n",
    "    test_subject = subject(151, 2990, 5000, 16)\n",
    "elif test_subject_id == 'Patient_3':\n",
    "    test_subject = subject(327, 714, 5000, 55)\n",
    "elif test_subject_id == 'Patient_4':\n",
    "    test_subject = subject(20, 190, 5000, 72)    \n",
    "elif test_subject_id == 'Patient_5':\n",
    "    test_subject = subject(135, 2610, 5000, 64) \n",
    "elif test_subject_id == 'Patient_6':\n",
    "    test_subject = subject(225, 2772, 5000, 30) \n",
    "elif test_subject_id == 'Patient_7':\n",
    "    test_subject = subject(282, 3239, 5000, 36) \n",
    "elif test_subject_id == 'Patient_8':\n",
    "    test_subject = subject(180, 1710, 5000, 16) \n",
    "\n",
    " \n",
    "dir_in = 'D:\\\\Romanlab\\XT_DataSet\\dataset2\\\\' + test_subject_id + '\\\\' + test_subject_id \n",
    "dir_ou = 'D:\\\\Romanlab\\XT_DataSet\\dataset2\\\\' + test_subject_id + 'OG3\\\\'   \n",
    "\n",
    "k = 5  # K-fold \n",
    "Xic, yic, Xit, yit = xt_load_rawdata(test_subject, filter_en, resample_en, dir_in)\n",
    "\n",
    "xt_prep_dataset(test_subject, dir_ou, k, Xic, yic, Xit, yit, norm_en, filter_en, shuffle_train_en)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1) Combine 4 train_i sets of Dog1, ..., Dog4 into 1 train_i\n",
    "# 2) Combine 4 test_i sets of Dog1, ..., Dog4 into 1 test_i\n",
    "# ============================================\n",
    "def xt_concat_dataset(subject, n_subject, kfold, dir_in, dir_ou):\n",
    "\n",
    "    dataset = ['train', 'test']\n",
    "\n",
    "    for d in range (0, 2):\n",
    "        #\n",
    "        for j in range (0, kfold):\n",
    "            #\n",
    "            Xy = []\n",
    "            for i in range (1, n_subject + 1):\n",
    "                file_in = dir_in + 'Dog_' + str(i) + 'OB\\\\' + dataset[d] + '_' + str(j)\n",
    "                print('Read file', file_in)\n",
    "                Xy_tmp = np.loadtxt(file_in, delimiter=' ', usecols=(range(0, 17)))\n",
    "                if i == 1:\n",
    "                    Xy = Xy_tmp\n",
    "                else:\n",
    "                    Xy = np.concatenate((Xy, Xy_tmp), axis=0)\n",
    "\n",
    "            file_ou = dir_ou + dataset[d] + '_' + str(j)\n",
    "            print('Write file', file_ou)\n",
    "\n",
    "            # 3D-to-2D\n",
    "            Xy = np.asarray(Xy)\n",
    "            dim = Xy.shape\n",
    "            print('--- Shape of Xy', dim)\n",
    "            np.savetxt(file_ou, Xy, delimiter=' ', fmt = '%.4f')\n",
    "    \n",
    "    \n",
    "# =========================================================\n",
    "# Test function\n",
    "# =========================================================\n",
    "dir_in = 'D:\\\\Romanlab\\XT_DataSet\\dataset2\\\\'\n",
    "dir_ou = 'D:\\\\Romanlab\\XT_DataSet\\dataset2\\Dog_OB\\\\'\n",
    "kfold = 5\n",
    "n_subject = 4\n",
    "\n",
    "xt_concat_dataset(subject, n_subject, kfold, dir_in, dir_ou)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check historam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dir_in = 'D:\\\\Romanlab\\\\XT_DataSet\\\\dataset2\\\\Dog_1OU\\\\non_std\\\\'\n",
    "dir_in = 'D:\\\\Romanlab\\\\XT_DataSet\\\\dataset2\\\\Patient_6OG\\\\'\n",
    "fileID = 0 \n",
    "n_timestep = 500 #400\n",
    "n_channel= 30\n",
    "\n",
    "\n",
    "file_train = dir_in + 'train_' + str(fileID) \n",
    "\n",
    "X_train = np.loadtxt(file_train, delimiter=' ', usecols=(range(0, n_channel))) \n",
    "#X_train = np.loadtxt(file_train, delimiter=' ', usecols=(10)) \n",
    "\n",
    "fig=plt.figure(figsize=(18, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(X_train, bins=200) \n",
    "#plt.axis([-500, 500, 0, 1000000]) \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(X_train, bins=200) \n",
    "plt.axis([-20, 20, 0, 800000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(X_train, return_counts=True)\n",
    "dim = values.shape \n",
    "tmp_values = values.reshape((dim[0], 1))\n",
    "tmp_counts = counts.reshape((dim[0], 1)) \n",
    "\n",
    "tmp = np.hstack((tmp_values, tmp_counts ))\n",
    "\n",
    "np.savetxt('./Results_copy1/histogram_norm_patient3', tmp, fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score \n",
    "\n",
    "\n",
    "#file_in = '.\\Results\\\\test-pred--date--id.k.bs.cw.hu1.hu2.hu3--2018.07.23.12.16--Dog_.0.64.1.32.0.0'\n",
    "file_in = '.\\Results\\\\20180723_Dog_CDLDAD_AUC\\\\test-pred--date--id.k.bs.cw.hu1.hu2.hu3--2018.07.23.05.55--Dog_.4.64.1.32.0.0'\n",
    "\n",
    "#X_train = np.loadtxt(file_train, delimiter=' ', usecols=(range(9, 9))) \n",
    "[y_test, y_pred] = np.loadtxt(file_in, delimiter=' ') \n",
    "print(y_test.shape, y_pred.shape)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "start = 15000\n",
    "end = 50000 #y_test.shape[0]\n",
    "t = range (start, end)\n",
    "\n",
    "# ==============================================\n",
    "print('=== Raw results === ')\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.fill_between(t, y_test[start:end], facecolor='yellow')\n",
    "#plt.fill_between(t, y_pred[start:end], facecolor='red')\n",
    "#plt.plot(t, y_test[start:end], color='r') \n",
    "#plt.plot(t, y_pred[start:end], color='b', linestyle=':')\n",
    "plt.title('y_test vs y_pred')\n",
    "plt.ylabel('Class')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "y_diff = y_test != y_pred\n",
    "#plt.plot(t, y_diff[start:end], color='b') \n",
    "plt.fill_between(t, y_pred[start:end], facecolor='red')\n",
    "plt.title('y_diff')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Class')\n",
    "print('Diff =', np.sum(y_diff))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "sens = tp/(tp + fn)\n",
    "spec = tn/(fp + tn)\n",
    "print(tn, fp, fn, tp, sens, spec)\n",
    "\n",
    "# ==============================================\n",
    "print('=== Filtered results === ')\n",
    "prev_value = 1\n",
    "threshold = 80\n",
    "y_pred_avg = np.ones(y_pred.shape[0])\n",
    "p = 0.995   \n",
    "\n",
    "for i in range (0, y_pred.shape[0] ):\n",
    "    if i == 0:\n",
    "        y_pred_avg[i] = y_pred[i]\n",
    "    else:\n",
    "        y_pred_avg[i] = y_pred[i] * (1 - p) + y_pred_avg[i-1] * p\n",
    "        \n",
    "y_pred_avg = np.round(y_pred_avg)        \n",
    "        \n",
    "plt.subplot(4, 1, 3)\n",
    "plt.fill_between(t, y_test[start:end], facecolor='yellow')\n",
    "plt.fill_between(t, y_pred_avg[start:end], facecolor='red')\n",
    "#plt.plot(t, y_test[start:end], color='r') \n",
    "#plt.plot(t, y_pred[start:end], color='b', linestyle=':')\n",
    "plt.title('y_test vs y_pred')\n",
    "plt.ylabel('Class')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "y_diff = y_test != y_pred_avg \n",
    "plt.plot(t, y_diff[start:end], color='b') \n",
    "plt.title('y_diff')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Class')\n",
    "print('Diff =', np.sum(y_diff))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_avg).ravel()\n",
    "sens = tp/(tp + fn)\n",
    "spec = tn/(fp + tn)\n",
    "print(tn, fp, fn, tp, sens, spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
